{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSV_OlCFKOD"
   },
   "source": [
    "# Laod data and prepare it\n",
    "This simple example demonstrates how to plug TensorFlow Datasets (TFDS) into a Keras model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TTBSvHcSLBzc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:12:06.522999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 21:12:06.523039: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import time\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUMhCXhFXdHQ",
    "outputId": "db61f7e1-2f58-47a6-dc93-6d2853502cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "n_Ws7js48FGI",
    "outputId": "b56caf92-7be8-4748-ab9b-dfcd2cd6b1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fecd51cd580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1rhSpKtEuD6C"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "# Method to shift the image by given dimension\n",
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "18xqJkKTUAh0"
   },
   "outputs": [],
   "source": [
    "idxs = np.ones(100)\n",
    "for digit in range(10):\n",
    "  digit_args = np.argwhere(y_train == digit)[:10,0]\n",
    "  np.random.shuffle(digit_args)\n",
    "  idxs[digit*10:(digit+1)*10] = digit_args\n",
    "np.random.shuffle(idxs)\n",
    "idxs = list(idxs.astype(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i7nS0QkEvoML"
   },
   "outputs": [],
   "source": [
    "x_train_labeled = x_train[idxs]\n",
    "y_train_labeled = y_train[idxs]\n",
    "x_train_unlabeled_original = np.delete(x_train.copy(), idxs, axis=0)\n",
    "x_train_unlabeled = x_train_unlabeled_original[:int(x_train_unlabeled_original.shape[0]/2)] \n",
    "# Creating Augmented Dataset\n",
    "# x_train_augmented = x_train_unlabeled_original[int(x_train_unlabeled_original.shape[0]/2):] \n",
    "x_train_augmented = []\n",
    "for image in x_train_unlabeled:\n",
    "    x_train_augmented.append(np.expand_dims(shift_image(image, 3, 3), axis=-1))\n",
    "x_train_augmented = np.array(x_train_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwtyPq4_0De9"
   },
   "source": [
    "## Seperate the unlabeled images into original and augmeneted images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YKigGgCD7z-_"
   },
   "outputs": [],
   "source": [
    "digit_idxs = {}\n",
    "for digit in range(10):\n",
    "  digit_args = np.argwhere(y_train == digit)[:,0]\n",
    "  np.random.shuffle(digit_args)\n",
    "  digit_idxs[digit] = list(digit_args.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiCgcetk8fIT",
    "outputId": "2f55d71a-b1d4-4c00-b47f-30c21fef4f30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2710"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt_per_class = int(min([len(idxs) for idxs in digit_idxs.values()]) / 2)\n",
    "elt_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9qT0_vqG9gqV"
   },
   "outputs": [],
   "source": [
    "digit_data = {}\n",
    "digit_label = {}\n",
    "for digit in np.unique(y_train):\n",
    "  digit_data[digit] = ( x_train[ digit_idxs[digit][:elt_per_class] ] , x_train[ digit_idxs[digit][elt_per_class:elt_per_class*2] ])\n",
    "  digit_label[digit] = ( y_train[ digit_idxs[digit][:elt_per_class] ] , y_train[ digit_idxs[digit][elt_per_class:elt_per_class*2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZaWtgfQZ_E5M"
   },
   "outputs": [],
   "source": [
    "original_data = None\n",
    "original_labels = None\n",
    "for digit in np.unique(y_train):\n",
    "  if original_data is None:\n",
    "    original_data = digit_data[digit][0]\n",
    "    original_labels = digit_label[digit][0]\n",
    "  else:\n",
    "    original_data = np.concatenate((original_data, digit_data[digit][0]))\n",
    "    original_labels = np.concatenate((original_labels, digit_label[digit][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nR0cJDbnAxs_"
   },
   "outputs": [],
   "source": [
    "augmented_data = None\n",
    "augmented_labels = None\n",
    "for digit in np.unique(y_train):\n",
    "  if augmented_data is None:\n",
    "    augmented_data = digit_data[digit][1]\n",
    "    augmented_labels = digit_label[digit][1]\n",
    "  else:\n",
    "    augmented_data = np.concatenate((augmented_data, digit_data[digit][1]))\n",
    "    augmented_labels = np.concatenate((augmented_labels, digit_label[digit][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YDvlNdtuBvkn"
   },
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(original_data.shape[0])\n",
    "augmented_data, original_data, augmented_labels, original_labels = augmented_data[permutation], original_data[permutation], augmented_labels[permutation], original_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niiyeDsDA2jH",
    "outputId": "cbffcfb5-9cd0-4355-f181-4c9c39f05b9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.equal(augmented_labels, original_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZUKNoFt5rzZ",
    "outputId": "50f3874f-3894-4d72-c0a6-4177524af542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27100, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPIlp8pt5uNa",
    "outputId": "82769ae0-fd43-4276-b27e-599d03ff17a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27100, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "J4mLEfhOPliJ",
    "outputId": "8312b544-09e1-4d24-9fb3-34466ebd474b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecd4f6c8b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(augmented_labels[0])\n",
    "\n",
    "plt.imshow(augmented_data[0, :, :, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "p9E9qXEo6AW6",
    "outputId": "713bf6fd-148f-4bed-f743-7e76e8b8fd42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecd4ed6f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(original_data[0, :, :, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Neovg7jzeGyQ"
   },
   "source": [
    "# New Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sFn6gBX4Xr7_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:12:18.707815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-10 21:12:18.707853: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-10 21:12:18.707882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2021-12-10 21:12:18.708095: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28,28), name=\"digits\")\n",
    "x1 = keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x1)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a960ShGDbsop"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(5e-4), \n",
    "                              # kernel_initializer=keras.initializers.he_normal\n",
    "                             ),\n",
    "        tf.keras.layers.Dense(10, name=\"classifier\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eJtguCpGX8JO"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WIfpIc2oYgh0"
   },
   "outputs": [],
   "source": [
    "labels_per_batch=10\n",
    "unlabels_per_batch=59\n",
    "all_x = None\n",
    "for i in range(int(100/labels_per_batch)):\n",
    "    if all_x is None:\n",
    "        all_x = np.concatenate((x_train_labeled[i*labels_per_batch:i*labels_per_batch+labels_per_batch], x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch], x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]))\n",
    "    else:\n",
    "        all_x = np.concatenate((all_x,x_train_labeled[i*labels_per_batch:i*labels_per_batch+labels_per_batch], x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch], x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KY1O4vZ-dVNm",
    "outputId": "7a7a90ad-bd02-4535-9ea5-539340546069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3JpHTH_LcWJd"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zMBWC3G0ctWM"
   },
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pH8a26LvYI6_",
    "outputId": "941674ba-8c00-4f8e-9d77-ce5e3d34e8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 2.2453\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.1500\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 1.2183\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.8000\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.7841\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.8600\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.5240\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9200\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.3538\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9500\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.2274\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9700\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.1458\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9900\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.0988\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 1.0000\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.0729\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 1.0000\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.0567\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step in range(math.ceil(all_x.shape[0]/batch_size)):\n",
    "        x_batch_train = all_x[step*batch_size:step*batch_size+labels_per_batch]\n",
    "        y_batch_train = y_train_labeled[step*labels_per_batch:step*labels_per_batch+labels_per_batch]\n",
    "\n",
    "        # x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch]\n",
    "        # x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, logits[:labels_per_batch])\n",
    "\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits[:labels_per_batch])\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * 64))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUeE13HCcm1c",
    "outputId": "e249641f-c0cb-498b-a0c6-7fd04e8f4b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.6991\n"
     ]
    }
   ],
   "source": [
    "for x_batch_val, y_batch_val in val_dataset:\n",
    "    val_logits = model(x_batch_val, training=False)\n",
    "    # Update val metrics\n",
    "    val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "val_acc = val_acc_metric.result()\n",
    "val_acc_metric.reset_states()\n",
    "print(\"Validation acc: %.4f\" % (float(val_acc),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaztNgM9gBj-"
   },
   "source": [
    "# Research Paper Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-t_1pH5MgORE"
   },
   "outputs": [],
   "source": [
    "def _kl_divergence_with_logits(p_logits, q_logits):\n",
    "  p = tf.nn.softmax(p_logits)\n",
    "  log_p = tf.nn.log_softmax(p_logits)\n",
    "  log_q = tf.nn.log_softmax(q_logits)\n",
    "\n",
    "  kl = tf.reduce_sum(p * (log_p - log_q), -1)\n",
    "  return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-5mnovqSa-Vz"
   },
   "outputs": [],
   "source": [
    "def get_ent(logits, return_mean=True):\n",
    "  log_prob = tf.nn.log_softmax(logits, axis=-1)\n",
    "  prob = tf.exp(log_prob)\n",
    "  ent = tf.reduce_sum(-prob * log_prob, axis=-1)\n",
    "  if return_mean:\n",
    "    ent = tf.reduce_mean(ent)\n",
    "  return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RGgYZnz_UsHy"
   },
   "outputs": [],
   "source": [
    "def get_tsa_threshold(schedule, global_step, num_train_steps, start, end):\n",
    "    step_ratio = float(global_step) / float(num_train_steps)\n",
    "    if schedule == \"linear_schedule\":\n",
    "        coeff = step_ratio\n",
    "    elif schedule == \"exp_schedule\":\n",
    "        scale = 5\n",
    "        # [exp(-5), exp(0)] = [1e-2, 1]\n",
    "        coeff = tf.exp((step_ratio - 1) * scale)\n",
    "    elif schedule == \"log_schedule\":\n",
    "        scale = 5\n",
    "    # [1 - exp(0), 1 - exp(-5)] = [0, 0.99]\n",
    "        coeff = 1 - tf.exp((-step_ratio) * scale)\n",
    "    return coeff * (end - start) + start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3Qgn7O0jUkF5"
   },
   "outputs": [],
   "source": [
    "def anneal_sup_loss(sup_logits, sup_labels, sup_loss, global_step, nbr_steps, num_classes, tsa_schedule):\n",
    "  tsa_start = 1. / num_classes\n",
    "  eff_train_prob_threshold = get_tsa_threshold(\n",
    "      tsa_schedule, global_step, nbr_steps,\n",
    "      tsa_start, end=1)\n",
    "  one_hot_labels = tf.one_hot(\n",
    "      sup_labels, depth=num_classes, dtype=tf.float32)\n",
    "  sup_probs = tf.nn.softmax(sup_logits, axis=-1)\n",
    "  correct_label_probs = tf.reduce_sum(\n",
    "      one_hot_labels * sup_probs, axis=-1)\n",
    "  larger_than_threshold = tf.greater(\n",
    "      correct_label_probs, eff_train_prob_threshold)\n",
    "  loss_mask = 1 - tf.cast(larger_than_threshold, tf.float32)\n",
    "  loss_mask = tf.stop_gradient(loss_mask)\n",
    "  sup_loss = sup_loss * loss_mask\n",
    "  avg_sup_loss = (tf.reduce_sum(sup_loss) /\n",
    "                  tf.maximum(tf.reduce_sum(loss_mask), 1))\n",
    "  return sup_loss, avg_sup_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2t6TZmlrqEd2"
   },
   "source": [
    "# Model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bCYF7QA_qGHu"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_train(hyper, epochs=10, pretraining=False, verbose=False):\n",
    "    \n",
    "    hyper = copy.deepcopy(hyper)\n",
    "    model = keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(hyper[\"l2\"]), \n",
    "                              # kernel_initializer=keras.initializers.he_normal\n",
    "                             ),\n",
    "        tf.keras.layers.Dropout(hyper[\"dropout\"]),\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(hyper[\"l2\"]), \n",
    "                              # kernel_initializer=keras.initializers.he_normal\n",
    "                             ),\n",
    "        tf.keras.layers.Dropout(hyper[\"dropout\"]),\n",
    "                              # kernel_initializer=keras.initializers.he_normal\n",
    "                             \n",
    "        tf.keras.layers.Dense(10, name=\"classifier\")\n",
    "    ])\n",
    "\n",
    "    hyper[\"optimizer\"] = keras.optimizers.Adam()\n",
    "    hyper[\"loss_fn\"] = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    hyper[\"train_acc_metric\"] = keras.metrics.SparseCategoricalAccuracy()\n",
    "    hyper[\"val_acc_metric\"] = keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    val_dataset = val_dataset.batch(128)\n",
    "    \n",
    "    if pretraining:\n",
    "        print(\"Starting Pretraining\")\n",
    "        pretrain(model, x_train_labeled, y_train_labeled, val_dataset, epochs)\n",
    "    print(\"Starting Training\")\n",
    "    train(model, x_train_labeled,original_data,augmented_data, val_dataset, hyper, epochs, verbose=verbose )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tNSsWB_nqG-s"
   },
   "outputs": [],
   "source": [
    "def pretrain(model, x_train, y_train,val_dataset, epochs=10, verbose=False):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_dataset,\n",
    "        verbose=0\n",
    "    )\n",
    "    print(\"Pretraining Validation Accuracy: %.4f \\n\\n\" % model.evaluate(val_dataset, batch_size=128)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "G8XnFzMxqMXq"
   },
   "outputs": [],
   "source": [
    "def train(model,x_train_labeled,original_data,augmented_data,val_dataset, hyper, epochs=10, verbose=False):\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        val_acc_metric.update_state(y, val_logits)\n",
    "    \n",
    "    unlabels_per_batch = hyper[\"unlabels_per_batch\"]\n",
    "    batch_unique_labels = hyper[\"batch_unique_labels\"]\n",
    "    labels_per_batch = hyper[\"labels_per_batch\"]\n",
    "    hyper[\"labels_per_batch\"]\n",
    "    \n",
    "    optimizer = hyper[\"optimizer\"] \n",
    "    loss_fn = hyper[\"loss_fn\"] \n",
    "    train_acc_metric = hyper[\"train_acc_metric\"]\n",
    "    val_acc_metric = hyper[\"val_acc_metric\"]\n",
    "    tsa_schedule = hyper[\"tsa_schedule\"]\n",
    "    num_classes = hyper[\"num_classes\"]\n",
    "    uda_softmax_temp = hyper[\"uda_softmax_temp\"]\n",
    "    uda_confidence_thresh = hyper[\"uda_confidence_thresh\"]\n",
    "    ent_min_coeff = hyper[\"ent_min_coeff\"]\n",
    "    lamd = hyper[\"lamd\"]\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        if(verbose):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step in range(int(original_data.shape[0]/unlabels_per_batch)):\n",
    "            sup_images = x_train_labeled[int(step % batch_unique_labels)*labels_per_batch:int(step % batch_unique_labels)*labels_per_batch+labels_per_batch]\n",
    "            ori_images = original_data[step*unlabels_per_batch: step*unlabels_per_batch+unlabels_per_batch]\n",
    "            aug_images = augmented_data[step*unlabels_per_batch: step*unlabels_per_batch+unlabels_per_batch]\n",
    "\n",
    "            # x_batch_train = all_x[step*batch_size:step*batch_size+batch_size]\n",
    "            x_batch_train = np.concatenate((sup_images, ori_images, aug_images))\n",
    "            y_batch_train = y_train_labeled[int(step % batch_unique_labels)*labels_per_batch:int(step % batch_unique_labels)*labels_per_batch+labels_per_batch]\n",
    "\n",
    "            # x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch]\n",
    "            # x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]\n",
    "            # Open a GradientTape to record the operations run\n",
    "            # during the forward pass, which enables auto-differentiation.\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                # Run the forward pass of the layer.\n",
    "                # The operations that the layer applies\n",
    "                # to its inputs are going to be recorded\n",
    "                # on the GradientTape.\n",
    "                logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "                # Compute the loss value for this minibatch.\n",
    "                sup_logits = logits[:labels_per_batch]\n",
    "                sup_loss = loss_fn(y_batch_train, sup_logits)\n",
    "\n",
    "                # Use TSA training loss\n",
    "                if tsa_schedule:\n",
    "                    sup_loss, avg_sup_loss = anneal_sup_loss(sup_logits, y_batch_train, sup_loss, epoch, epochs, num_classes, tsa_schedule)\n",
    "                else:\n",
    "                    avg_sup_loss = tf.reduce_mean(sup_loss)\n",
    "                total_loss = avg_sup_loss\n",
    "\n",
    "                # Get loss from the unlabled data \n",
    "\n",
    "                # logits of unlabled real images\n",
    "                ori_logits = logits[labels_per_batch : labels_per_batch + unlabels_per_batch]\n",
    "                # logits of unlabeled augmented images\n",
    "                aug_logits = logits[labels_per_batch + unlabels_per_batch : ]\n",
    "\n",
    "                #Sharpening predictions for the kl divergence\n",
    "                if uda_softmax_temp != -1:\n",
    "                    ori_logits_tgt = ori_logits / uda_softmax_temp\n",
    "                else:\n",
    "                    ori_logits_tgt = ori_logits\n",
    "\n",
    "                # Calculate KL divergence\n",
    "                aug_loss = _kl_divergence_with_logits(\n",
    "                    p_logits=tf.stop_gradient(ori_logits_tgt),\n",
    "                    q_logits=aug_logits)\n",
    "\n",
    "                if uda_confidence_thresh != -1:\n",
    "                    ori_prob = tf.nn.softmax(ori_logits, axis=-1)\n",
    "                    largest_prob = tf.reduce_max(ori_prob, axis=-1)\n",
    "                    loss_mask = tf.cast(tf.greater(\n",
    "                        largest_prob, uda_confidence_thresh), tf.float32)\n",
    "                    loss_mask = tf.stop_gradient(loss_mask)\n",
    "                    aug_loss = aug_loss * loss_mask\n",
    "\n",
    "                if ent_min_coeff > 0:\n",
    "                    per_example_ent = get_ent(ori_logits)\n",
    "                    ent_min_loss = tf.reduce_mean(per_example_ent)\n",
    "                    total_loss = total_loss + ent_min_coeff * ent_min_loss\n",
    "                \n",
    "                avg_unsup_loss = tf.reduce_mean(aug_loss)\n",
    "\n",
    "                total_loss += lamd * avg_unsup_loss\n",
    "\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = tape.gradient(total_loss, model.trainable_weights)\n",
    "\n",
    "            # Run one step of gradient descent by updating\n",
    "            # the value of the variables to minimize the loss.\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            # Update training metric.\n",
    "            train_acc_metric.update_state(y_batch_train, logits[:labels_per_batch])\n",
    "\n",
    "            if verbose:\n",
    "                # Log every 200 batches.\n",
    "                if step % 50 == 0:\n",
    "                    print(\n",
    "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                        % (step, float(total_loss))\n",
    "                    )\n",
    "                    print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "        # Display metrics at the end of each epoch.\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        train_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        if verbose:\n",
    "            print(\"Time taken: %.2fs \\n\" % (time.time() - start_time))\n",
    "    return float(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WlWKPDuT1yr4"
   },
   "outputs": [],
   "source": [
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "zZVTyyvYqPVu"
   },
   "outputs": [],
   "source": [
    "labels_per_batch = 50\n",
    "batch_size = 128\n",
    "\n",
    "hyper = {\n",
    "    \"labels_per_batch\":labels_per_batch,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"batch_unique_labels\":100/labels_per_batch,\n",
    "    \"unlabels_per_batch\":int((batch_size-labels_per_batch)/2),\n",
    "    \"nbr_batch\" : 100,\n",
    "    \"lamd\" : 1,\n",
    "    \"tsa_schedule\":\"exp_schedule\",\n",
    "    # tsa_schedule=\"\"\n",
    "    \"num_classes\" : 10,\n",
    "    \"uda_softmax_temp\" : 0.9,\n",
    "    \"uda_confidence_thresh\" : 0.8,\n",
    "    \"ent_min_coeff\" : 0.5,\n",
    "\n",
    "    \"num_classes\" : 10,\n",
    "    \"decay_steps\" : 1000,\n",
    "    \"moving_average_decay\":0.9999,\n",
    "    \"initial_learning_rate\":1e-2,\n",
    "    \"dropout\":0.8,\n",
    "    \"l2\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHYqopfXqQie",
    "outputId": "748ab71e-2e7b-4d67-ce9c-c5a52415f95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:14<02:06, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7488\n",
      "Training acc over epoch: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [00:28<01:52, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:43<01:42, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9297\n",
      "Validation acc: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [00:57<01:26, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9439\n",
      "Validation acc: 0.7974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [01:10<01:10, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9515\n",
      "Validation acc: 0.8099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [01:24<00:55, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9545\n",
      "Validation acc: 0.8149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [01:37<00:40, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9593\n",
      "Validation acc: 0.8277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [01:51<00:27, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acc over epoch: 0.9665\n",
      "Validation acc: 0.8340\n",
      "Training acc over epoch: 0.9697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [02:05<00:13, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8323\n",
      "Training acc over epoch: 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [02:20<00:00, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc: 0.8347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_train(hyper, epochs=10, pretraining=False, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "N0n-M1Xpd-fl",
    "yO8OPXjJgFE3"
   ],
   "name": "DeepL_Project",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
